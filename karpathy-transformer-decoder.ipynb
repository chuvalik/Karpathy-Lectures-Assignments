{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch \nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T15:33:22.420946Z","iopub.execute_input":"2023-09-14T15:33:22.421339Z","iopub.status.idle":"2023-09-14T15:33:22.426299Z","shell.execute_reply.started":"2023-09-14T15:33:22.421308Z","shell.execute_reply":"2023-09-14T15:33:22.425342Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:33:22.431862Z","iopub.execute_input":"2023-09-14T15:33:22.432126Z","iopub.status.idle":"2023-09-14T15:33:34.695269Z","shell.execute_reply.started":"2023-09-14T15:33:22.432103Z","shell.execute_reply":"2023-09-14T15:33:34.693690Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.5.1)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tiktoken","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:33:34.699070Z","iopub.execute_input":"2023-09-14T15:33:34.699996Z","iopub.status.idle":"2023-09-14T15:33:34.707250Z","shell.execute_reply.started":"2023-09-14T15:33:34.699962Z","shell.execute_reply":"2023-09-14T15:33:34.706308Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:33:34.710580Z","iopub.execute_input":"2023-09-14T15:33:34.710998Z","iopub.status.idle":"2023-09-14T15:33:35.787484Z","shell.execute_reply.started":"2023-09-14T15:33:34.710968Z","shell.execute_reply":"2023-09-14T15:33:35.786283Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"--2023-09-14 15:33:35--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: ‘input.txt.1’\n\ninput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n\n2023-09-14 15:33:35 (24.6 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"filename = \"/kaggle/working/input.txt\"\n\ntext = None\nwith open(filename, 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:33:35.792101Z","iopub.execute_input":"2023-09-14T15:33:35.792440Z","iopub.status.idle":"2023-09-14T15:33:35.799603Z","shell.execute_reply.started":"2023-09-14T15:33:35.792401Z","shell.execute_reply":"2023-09-14T15:33:35.798507Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"Length of the text: {}\".format(len(text)))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:33:35.801000Z","iopub.execute_input":"2023-09-14T15:33:35.801500Z","iopub.status.idle":"2023-09-14T15:33:35.809833Z","shell.execute_reply.started":"2023-09-14T15:33:35.801468Z","shell.execute_reply":"2023-09-14T15:33:35.808800Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Length of the text: 1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"print(text[:1000])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:41:52.858339Z","iopub.execute_input":"2023-09-14T15:41:52.859199Z","iopub.status.idle":"2023-09-14T15:41:52.865362Z","shell.execute_reply.started":"2023-09-14T15:41:52.859164Z","shell.execute_reply":"2023-09-14T15:41:52.864427Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(\"\".join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:41:52.972662Z","iopub.execute_input":"2023-09-14T15:41:52.973242Z","iopub.status.idle":"2023-09-14T15:41:52.996342Z","shell.execute_reply.started":"2023-09-14T15:41:52.973204Z","shell.execute_reply":"2023-09-14T15:41:52.995370Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:41:53.115562Z","iopub.execute_input":"2023-09-14T15:41:53.116337Z","iopub.status.idle":"2023-09-14T15:41:53.121150Z","shell.execute_reply.started":"2023-09-14T15:41:53.116302Z","shell.execute_reply":"2023-09-14T15:41:53.120041Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"stoi = {char: idx for idx, char in enumerate(chars)}\nitos = {idx: char for idx, char in enumerate(chars)}\n\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda n: \"\".join(itos[i] for i in n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:41:53.251684Z","iopub.execute_input":"2023-09-14T15:41:53.252240Z","iopub.status.idle":"2023-09-14T15:41:53.258065Z","shell.execute_reply.started":"2023-09-14T15:41:53.252206Z","shell.execute_reply":"2023-09-14T15:41:53.257052Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"print(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:41:53.380018Z","iopub.execute_input":"2023-09-14T15:41:53.380297Z","iopub.status.idle":"2023-09-14T15:41:53.385423Z","shell.execute_reply.started":"2023-09-14T15:41:53.380273Z","shell.execute_reply":"2023-09-14T15:41:53.384199Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"enc = tiktoken.get_encoding('gpt2')\nvocab_size = enc.n_vocab","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:48:22.353939Z","iopub.execute_input":"2023-09-14T15:48:22.354298Z","iopub.status.idle":"2023-09-14T15:48:22.359100Z","shell.execute_reply.started":"2023-09-14T15:48:22.354267Z","shell.execute_reply":"2023-09-14T15:48:22.358153Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"data = torch.tensor(enc.encode(text), dtype=torch.long)\nprint(data.shape, data.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:48:22.459191Z","iopub.execute_input":"2023-09-14T15:48:22.459820Z","iopub.status.idle":"2023-09-14T15:48:22.839056Z","shell.execute_reply.started":"2023-09-14T15:48:22.459781Z","shell.execute_reply":"2023-09-14T15:48:22.837935Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"torch.Size([338025]) torch.int64\n","output_type":"stream"}]},{"cell_type":"code","source":"n = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]\n\nprint(train_data.shape, val_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:48:22.841126Z","iopub.execute_input":"2023-09-14T15:48:22.841491Z","iopub.status.idle":"2023-09-14T15:48:22.849998Z","shell.execute_reply.started":"2023-09-14T15:48:22.841457Z","shell.execute_reply":"2023-09-14T15:48:22.849069Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"torch.Size([304222]) torch.Size([33803])\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 8\nblock_size = 128\nmax_iters = 5000\nlr = 3e-4\neval_iters = 200\nn_embed = 384\nn_head = 6\nn_layers = 6\ndropout = 0.15","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:33.752954Z","iopub.execute_input":"2023-09-14T16:03:33.753484Z","iopub.status.idle":"2023-09-14T16:03:33.761303Z","shell.execute_reply.started":"2023-09-14T16:03:33.753440Z","shell.execute_reply":"2023-09-14T16:03:33.760335Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"def get_batch(split):\n    data = train_data if split == \"train\" else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n    return x, y\n\nxb, yb = get_batch(\"train\")\nprint('inputs: ')\nprint(xb.shape)\nprint(xb)\nprint(\"targets: \")\nprint(yb.shape)\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:33.895166Z","iopub.execute_input":"2023-09-14T16:03:33.895490Z","iopub.status.idle":"2023-09-14T16:03:33.909063Z","shell.execute_reply.started":"2023-09-14T16:03:33.895464Z","shell.execute_reply":"2023-09-14T16:03:33.908059Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"inputs: \ntorch.Size([8, 128])\ntensor([[ 1049, 15967,    11,  ...,   339,   319,   262],\n        [ 3440,    11,   198,  ...,    40, 12797,   262],\n        [  314,   750,  1011,  ...,   198,  7120,  1751],\n        ...,\n        [ 1276,   307, 14263,  ...,   621, 10938,    13],\n        [  273,   415, 19921,  ...,   373, 18988,    11],\n        [   48,  8924,  1677,  ..., 28356,   736,   286]], device='cuda:0')\ntargets: \ntorch.Size([8, 128])\ntensor([[15967,    11,   198,  ...,   319,   262,   835],\n        [   11,   198,  1532,  ..., 12797,   262, 21144],\n        [  750,  1011,   262,  ...,  7120,  1751,   547],\n        ...,\n        [  307, 14263,   276,  ..., 10938,    13,   198],\n        [  415, 19921,   307,  ..., 18988,    11,   198],\n        [ 8924,  1677,    25,  ...,   736,   286,  1918]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            x, y = get_batch(split)\n            logits, loss = model(x, y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.027264Z","iopub.execute_input":"2023-09-14T16:03:34.027789Z","iopub.status.idle":"2023-09-14T16:03:34.038517Z","shell.execute_reply.started":"2023-09-14T16:03:34.027762Z","shell.execute_reply":"2023-09-14T16:03:34.037438Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        \n        self.key = nn.Linear(n_embed, head_size, bias=False)\n        self.query = nn.Linear(n_embed, head_size, bias=False)\n        self.value = nn.Linear(n_embed, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.query(x)\n        \n        wei = q @ k.transpose(-2, -1) * C**-0.5\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        wei = F.softmax(wei, dim=-1)\n        \n        wei = self.dropout(wei)\n        \n        v = self.value(x)\n        out = wei @ v\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.186441Z","iopub.execute_input":"2023-09-14T16:03:34.186739Z","iopub.status.idle":"2023-09-14T16:03:34.195715Z","shell.execute_reply.started":"2023-09-14T16:03:34.186715Z","shell.execute_reply":"2023-09-14T16:03:34.194601Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.projection = nn.Linear(n_embed, n_embed)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(out)\n        return self.projection(out)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.313356Z","iopub.execute_input":"2023-09-14T16:03:34.313677Z","iopub.status.idle":"2023-09-14T16:03:34.322206Z","shell.execute_reply.started":"2023-09-14T16:03:34.313652Z","shell.execute_reply":"2023-09-14T16:03:34.319641Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, n_embed):\n        super().__init__()\n        \n        self.net = nn.Sequential(\n            nn.Linear(n_embed, 4 * n_embed),\n            nn.ReLU(),\n            nn.Linear(4 * n_embed, n_embed),\n            nn.Dropout(dropout)\n        )\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.435186Z","iopub.execute_input":"2023-09-14T16:03:34.435490Z","iopub.status.idle":"2023-09-14T16:03:34.441470Z","shell.execute_reply.started":"2023-09-14T16:03:34.435465Z","shell.execute_reply":"2023-09-14T16:03:34.440557Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, n_embed, n_head):\n        super().__init__()\n        head_size = n_embed // n_head\n        self.sa_heads = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedForward(n_embed)\n        self.ln1 = nn.LayerNorm(n_embed)\n        self.ln2 = nn.LayerNorm(n_embed)\n        \n    def forward(self, x):\n        x = x + self.sa_heads(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.571012Z","iopub.execute_input":"2023-09-14T16:03:34.571841Z","iopub.status.idle":"2023-09-14T16:03:34.578872Z","shell.execute_reply.started":"2023-09-14T16:03:34.571808Z","shell.execute_reply":"2023-09-14T16:03:34.577888Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"class BigramLanguageModel(nn.Module):\n    def __init__(self):\n        super(BigramLanguageModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, n_embed)\n        self.position_embedding = nn.Embedding(block_size, n_embed)\n        self.blocks = nn.Sequential(*[Block(n_embed, n_head) for _ in range(n_layers)])\n        self.ln_f = nn.LayerNorm(n_embed)\n        self.lm_head = nn.Linear(n_embed, vocab_size)\n        \n    def forward(self, src, tgt=None):\n        B, T = src.shape\n        \n        tok_emb = self.embedding(src) # (B, T, C)\n        pos_emb = self.position_embedding(torch.arange(T, device=device)) # (T, C)\n        x = tok_emb + pos_emb\n        x = self.blocks(x)\n        x = self.ln_f(x)\n        logits = self.lm_head(x)\n        \n        if tgt is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            tgt = tgt.view(B*T)\n            loss = F.cross_entropy(logits, tgt)\n\n        return logits, loss\n    \n    def generate(self, src, max_length):\n        for _ in range(max_length):\n            src_cond = src[:, -block_size:]\n            \n            logits, _ = self(src_cond)\n            \n            logits = logits[:, -1, :]\n            probs = F.softmax(logits, dim=1)\n            \n            idx_next = torch.multinomial(probs, num_samples=1)\n            src = torch.cat((src, idx_next), dim=1)\n            \n        return src\n    \nmodel = BigramLanguageModel().to(device)\nlogits, loss = model(xb, yb)\nprint(loss, logits.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:34.698341Z","iopub.execute_input":"2023-09-14T16:03:34.698670Z","iopub.status.idle":"2023-09-14T16:03:35.239199Z","shell.execute_reply.started":"2023-09-14T16:03:34.698637Z","shell.execute_reply":"2023-09-14T16:03:35.238229Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"tensor(11.0118, device='cuda:0', grad_fn=<NllLossBackward0>) torch.Size([1024, 50257])\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:35.241048Z","iopub.execute_input":"2023-09-14T16:03:35.241957Z","iopub.status.idle":"2023-09-14T16:03:35.249649Z","shell.execute_reply.started":"2023-09-14T16:03:35.241922Z","shell.execute_reply":"2023-09-14T16:03:35.248667Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"for iter in range(max_iters):\n    xb, yb = get_batch('train')\n    \n    if iter % eval_iters == 0:\n        losses = estimate_loss()\n        print(f\"step: {iter}; train_loss: {losses['train']}; val_loss: {losses['val']}\")\n    \n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n    \nprint(loss.item())","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:03:35.252497Z","iopub.execute_input":"2023-09-14T16:03:35.253059Z","iopub.status.idle":"2023-09-14T16:15:28.438924Z","shell.execute_reply.started":"2023-09-14T16:03:35.253026Z","shell.execute_reply":"2023-09-14T16:15:28.437914Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"step: 0; train_loss: 10.994235038757324; val_loss: 11.003198623657227\nstep: 200; train_loss: 5.455996513366699; val_loss: 5.717780590057373\nstep: 400; train_loss: 4.888713836669922; val_loss: 5.332345962524414\nstep: 600; train_loss: 4.616786956787109; val_loss: 5.077981948852539\nstep: 800; train_loss: 4.416253566741943; val_loss: 4.92218542098999\nstep: 1000; train_loss: 4.2369608879089355; val_loss: 4.829485893249512\nstep: 1200; train_loss: 4.085729598999023; val_loss: 4.810875415802002\nstep: 1400; train_loss: 3.9390952587127686; val_loss: 4.726984977722168\nstep: 1600; train_loss: 3.814293146133423; val_loss: 4.655821800231934\nstep: 1800; train_loss: 3.6938366889953613; val_loss: 4.703493595123291\nstep: 2000; train_loss: 3.6097042560577393; val_loss: 4.7000274658203125\nstep: 2200; train_loss: 3.5206191539764404; val_loss: 4.6884260177612305\nstep: 2400; train_loss: 3.4336087703704834; val_loss: 4.705157279968262\nstep: 2600; train_loss: 3.347733497619629; val_loss: 4.6924543380737305\nstep: 2800; train_loss: 3.259385108947754; val_loss: 4.6964497566223145\nstep: 3000; train_loss: 3.185319185256958; val_loss: 4.705207347869873\nstep: 3200; train_loss: 3.0904288291931152; val_loss: 4.7671709060668945\nstep: 3400; train_loss: 3.039059638977051; val_loss: 4.744760036468506\nstep: 3600; train_loss: 2.9014575481414795; val_loss: 4.816521167755127\nstep: 3800; train_loss: 2.8011319637298584; val_loss: 4.8395586013793945\nstep: 4000; train_loss: 2.740798234939575; val_loss: 4.849020004272461\nstep: 4200; train_loss: 2.6447980403900146; val_loss: 4.941970348358154\nstep: 4400; train_loss: 2.5417721271514893; val_loss: 4.953213214874268\nstep: 4600; train_loss: 2.4515671730041504; val_loss: 4.979379653930664\nstep: 4800; train_loss: 2.385895013809204; val_loss: 5.080099582672119\n2.5571296215057373\n","output_type":"stream"}]},{"cell_type":"code","source":"context = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(enc.decode(model.generate(context, 1000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:15:28.441248Z","iopub.execute_input":"2023-09-14T16:15:28.441624Z","iopub.status.idle":"2023-09-14T16:15:47.725868Z","shell.execute_reply.started":"2023-09-14T16:15:28.441589Z","shell.execute_reply":"2023-09-14T16:15:47.724797Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"!\n\nCOMINIUS:\nAnd welcome, they we have good cause in ourselves:\nGo whip you, fed home; take up, with us; for though we shall cry\n contradiction, and we shall find talk with cursing.\n\nJULIET:\n'Tis very road, well plainly I have trod measure in regard\nWhat is the night-faced day to chop night,\nThe blood o' the soldiers, the movingend here soundly urged,\nTo teeming foamingacles.\nSignior's not thy name, oldCourage; one with one:\nWhat say to me with thee? in Mantua,\n\nPAGE: and harlot people should fain\nThat marks thee in thy blessed ill in thee, that word:\nMore cruel for any more may behall:\nThou rather, who for the purpose that death\nFor that: therefore, I say! time thou art the likeness:\nAs likely a pale\nAnd yet, too careless, the meran when ever I see't.\n\nCORIOLANUS:\nSo I, a son?\nThere is this constant.\n\nSecond Messenger:\nHave you moved to took the city Corioli?\n\nSecond Messenger:\nCome, said, you shall bear the leisure to London.\nMoreover, fare you our own house,\nwill out a puissance may nurse to threw them now.\n\nSICINIUS:\nWhat's a common o' the mystery:\nYe'll walk; and, for that he do\nare many virtues: already passado!\nI something mother, that sir, and therein, as no\nCaius Marcius must enter\nAs you out in his abundance. He that's the very fairly bound to Rome,\nAnd shunn'd he made access to me:\nIf to be true Menenitoes' is much retired\nAmen or know, nought we rejoice in the field\nHe powers of dangerous malice.\nNurse:\nCome, then, he that he doth he dreams again:\nLeave nothing have no thought, but a day.\n\nROMEO:\nWell, bid me, dear an choice\nJULIET: on my biting laws for my lance's night\nThat's heavy heart's soft in Padua: 'Looking experience:\nI am I show it; and my master is a foolery,\nI have kept a Romeo: yet still awhile mask'd to Romeo:\nNow Romeo hide my Romeo for me,\nA crown, that my face to my arm'd spirit,\nI take my father from me from you,\nThou make the jest me king, as I do thrive in pity;\nA little while Verona by my humble son\nAs I mine own to combat and Romeo's night.\nWho knows I the King price of commanded?\nIs it a me; or else have ICare to Romeo,\nAs are minutes, my woe, by my care\nMy proud heart misbehaved-craz,\nYea whiles thy grave a way:\nAy, and all my youth, my old Adam shall suman's.\nCome, say you me your hand, that the air live,\nWhereto a two churchyard- office,\nHath she my sweet brother and rest:\nMy grave prince will be mild behavior prove so wed,\nThat see the rest, and my part of,\nSo cowards's nothing trembles: therefore me not a word,\nGlad rings whither: but sometimes, Harry, may I breathe,\nAnd joy.\n\nJULIET:\nWell, dishonour? Romeo, nurse, it is Tyrrel?\nThou place, Signior Baptista, thou wilt in thy lips.\n\nROMEO:\nAnd go along till more joyless time.\n\nJULIET:\nI go unto you fair: I'll kiss it one at night\nWilt thou not that, hasty like gods;\nPetitionershors will have my breath,\nFor so I was my valour.\n\nROMEO:\nO, my dear mother's love, I have not lend a dream!\nSome am in Corioli like the mouth:\n\nArt thou my love! 'Death, thoseong lives not wounds!\n\nJULIET:\nThese coals, nurse, for ever!\n\nROMEO:\nHere, then my dear friend, my sweet nurse.\nI will be the measure fit do.\nThis is thy company, behold a torch,\nFlower as a sight's nurse-leaf;\nAnd Romeo which looks so light a night\nUn newly only now but done is hid, and\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}